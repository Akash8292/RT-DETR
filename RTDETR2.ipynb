{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad9d828e4092455bb209015290d82a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed572fbbc10b4af78ee45ba397722355",
              "IPY_MODEL_70bd4b1c62e34ac3ad9da876e8510f5b",
              "IPY_MODEL_99bd57ab52f04992bcaef8f161ef566d"
            ],
            "layout": "IPY_MODEL_9bd0264f0dfb4fd7aa3beddb817b1668"
          }
        },
        "ed572fbbc10b4af78ee45ba397722355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08389032e9a943a5b193e2349f3829e1",
            "placeholder": "​",
            "style": "IPY_MODEL_e1096b3ea5794a3c8147935ac87ed2dd",
            "value": "Processing VisDrone2019-DET-train: 100%"
          }
        },
        "70bd4b1c62e34ac3ad9da876e8510f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c410411d5a04a23877639cd59404c5b",
            "max": 6471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a1f24ce331a49aba679526b117f962f",
            "value": 6471
          }
        },
        "99bd57ab52f04992bcaef8f161ef566d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fbc0898d56a41c0813aa75fbdf59d8d",
            "placeholder": "​",
            "style": "IPY_MODEL_82b23fd2d3b64968af909a662b35895c",
            "value": " 6471/6471 [00:55&lt;00:00, 67.55it/s]"
          }
        },
        "9bd0264f0dfb4fd7aa3beddb817b1668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08389032e9a943a5b193e2349f3829e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1096b3ea5794a3c8147935ac87ed2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c410411d5a04a23877639cd59404c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1f24ce331a49aba679526b117f962f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fbc0898d56a41c0813aa75fbdf59d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82b23fd2d3b64968af909a662b35895c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c93921d596e14dea85a6add6a12f5dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c581ee6853154e168ca598f4b4d65790",
              "IPY_MODEL_a869fec5d6e04230b3976f558044db91",
              "IPY_MODEL_65ddd14b4e6f455c934e78cb3e4298c3"
            ],
            "layout": "IPY_MODEL_ad31c0dbc5a3467e964cb5168491fd6e"
          }
        },
        "c581ee6853154e168ca598f4b4d65790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ba62ac867f8455db66fe6f25ed15a23",
            "placeholder": "​",
            "style": "IPY_MODEL_f0eac5ba26184c12a868059e5885b876",
            "value": "Processing VisDrone2019-DET-val: 100%"
          }
        },
        "a869fec5d6e04230b3976f558044db91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b05b71689104876a508f64a39c766da",
            "max": 548,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d53fe952e51d4bf0a2db488b17045835",
            "value": 548
          }
        },
        "65ddd14b4e6f455c934e78cb3e4298c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9539133b3fae49a48ea4f576ee88d7a0",
            "placeholder": "​",
            "style": "IPY_MODEL_ccc632bfc277493c9fd5c14271594688",
            "value": " 548/548 [00:02&lt;00:00, 197.45it/s]"
          }
        },
        "ad31c0dbc5a3467e964cb5168491fd6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba62ac867f8455db66fe6f25ed15a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0eac5ba26184c12a868059e5885b876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b05b71689104876a508f64a39c766da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53fe952e51d4bf0a2db488b17045835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9539133b3fae49a48ea4f576ee88d7a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccc632bfc277493c9fd5c14271594688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec701ed5da0d40d6bc2ac16770e5b178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6852728a3e84af7b33b8a27ce0744a2",
              "IPY_MODEL_c6413a25afeb411a945f6eb12085b28a",
              "IPY_MODEL_585c14ce5c2a482ba443bd5de91b9bc5"
            ],
            "layout": "IPY_MODEL_2b78686e4ac14efdbd6ad0581a5fa095"
          }
        },
        "a6852728a3e84af7b33b8a27ce0744a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d48527ceb8b4f678c57a31359eaa5b4",
            "placeholder": "​",
            "style": "IPY_MODEL_c2f94f92dfa44f33bcd96490dc3d2cab",
            "value": "Processing VisDrone2019-DET-test-dev: 100%"
          }
        },
        "c6413a25afeb411a945f6eb12085b28a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bad5c9fb34441f79407bc465be6ac1d",
            "max": 1610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28606494b0274f2e94b2604692259221",
            "value": 1610
          }
        },
        "585c14ce5c2a482ba443bd5de91b9bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_549da782432f4abe9ef9dfeaebb301e2",
            "placeholder": "​",
            "style": "IPY_MODEL_5e38d68183574d708c8ac7f8acab2d39",
            "value": " 1610/1610 [00:10&lt;00:00, 136.71it/s]"
          }
        },
        "2b78686e4ac14efdbd6ad0581a5fa095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d48527ceb8b4f678c57a31359eaa5b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f94f92dfa44f33bcd96490dc3d2cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bad5c9fb34441f79407bc465be6ac1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28606494b0274f2e94b2604692259221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "549da782432f4abe9ef9dfeaebb301e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e38d68183574d708c8ac7f8acab2d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akash8292/RT-DETR/blob/main/RTDETR2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RT-DETR Training on VisDrone Dataset\n",
        "\n",
        "This notebook guides you through setting up the RT-DETR environment, preparing the VisDrone dataset, and training the model in Google Colab."
      ],
      "metadata": {
        "id": "intro_markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Prerequisites\n",
        "\n",
        "1.  **Enable GPU:** Make sure you have enabled a GPU runtime in Colab (`Runtime` -> `Change runtime type` -> `Hardware accelerator` -> `GPU`).\n",
        "2.  **Upload Data:** Upload the following VisDrone zip files to the root directory of your Colab session (`/content/`):\n",
        "    *   `VisDrone2019-DET-train.zip`\n",
        "    *   `VisDrone2019-DET-val.zip`\n",
        "    *   `VisDrone2019-DET-test-dev.zip`"
      ],
      "metadata": {
        "id": "prereq_markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Force Remove Existing RT-DETR Directory (if it exists)\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "dir_to_remove = \"/content/RT-DETR\"\n",
        "\n",
        "if os.path.exists(dir_to_remove):\n",
        "  print(f\"Directory '{dir_to_remove}' exists. Removing it...\")\n",
        "  # Using shutil.rmtree is generally safer in Python than !rm -rf\n",
        "  try:\n",
        "      shutil.rmtree(dir_to_remove)\n",
        "      print(f\"✅ Successfully removed '{dir_to_remove}'.\")\n",
        "  except Exception as e:\n",
        "      print(f\"❌ Error removing directory with shutil: {e}\")\n",
        "      print(\"Attempting removal with shell command...\")\n",
        "      !rm -rf {dir_to_remove} # Use shell command as fallback\n",
        "      if not os.path.exists(dir_to_remove):\n",
        "           print(f\"✅ Successfully removed '{dir_to_remove}' using shell command.\")\n",
        "      else:\n",
        "           print(f\"❌ Failed to remove '{dir_to_remove}' even with shell command.\")\n",
        "else:\n",
        "    print(f\"Directory '{dir_to_remove}' does not exist. No need to remove.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxpGRoxtjzD5",
        "outputId": "7607228d-0a97-47e4-f427-eb898239dfe7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/RT-DETR' exists. Removing it...\n",
            "✅ Successfully removed '/content/RT-DETR'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Clone RT-DETR Repository\n",
        "!git clone https://github.com/lyuwenyu/RT-DETR.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clone_repo",
        "outputId": "094e5286-0a30-447f-8a32-1004771bff00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RT-DETR'...\n",
            "remote: Enumerating objects: 1020, done.\u001b[K\n",
            "remote: Counting objects: 100% (220/220), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 1020 (delta 145), reused 120 (delta 120), pack-reused 800 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1020/1020), 626.16 KiB | 22.36 MiB/s, done.\n",
            "Resolving deltas: 100% (496/496), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Change Directory to PyTorch Implementation\n",
        "%cd RT-DETR/rtdetrv2_pytorch\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "change_directory",
        "outputId": "4e1f8865-c9d1-4566-de10-98a33f721b95"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RT-DETR/rtdetrv2_pytorch\n",
            "/content/RT-DETR/rtdetrv2_pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Install Requirements\n",
        "!pip install -q -r requirements.txt\n",
        "# Install wget if not present (usually is in Colab)\n",
        "!apt-get install -qq wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_requirements",
        "outputId": "8d52ef46-e5ba-4aa2-9022-925540a116e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Download Pretrained Weights\n",
        "# Download the R50 VD pretrained weights (trained on COCO)\n",
        "!wget https://github.com/lyuwenyu/storage/releases/download/v0.1/rtdetr_r50vd_6x_coco_from_paddle.pth -O rtdetr_r50vd_6x_coco_from_paddle.pth\n",
        "print(\"✅ Pretrained weights downloaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "download_weights",
        "outputId": "2fc076c6-0956-4525-af88-ccbccd13913a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-01 08:56:36--  https://github.com/lyuwenyu/storage/releases/download/v0.1/rtdetr_r50vd_6x_coco_from_paddle.pth\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/676791659/bd85c705-7c81-4059-9a22-dbd22b0b8c29?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250401T085636Z&X-Amz-Expires=300&X-Amz-Signature=10a2a35065d7f742220e24cbcc96b7d4e8f7ea9722b62f3422d3d3fe86ad51eb&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Drtdetr_r50vd_6x_coco_from_paddle.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-04-01 08:56:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/676791659/bd85c705-7c81-4059-9a22-dbd22b0b8c29?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250401%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250401T085636Z&X-Amz-Expires=300&X-Amz-Signature=10a2a35065d7f742220e24cbcc96b7d4e8f7ea9722b62f3422d3d3fe86ad51eb&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Drtdetr_r50vd_6x_coco_from_paddle.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172373587 (164M) [application/octet-stream]\n",
            "Saving to: ‘rtdetr_r50vd_6x_coco_from_paddle.pth’\n",
            "\n",
            "rtdetr_r50vd_6x_coc 100%[===================>] 164.39M  14.3MB/s    in 13s     \n",
            "\n",
            "2025-04-01 08:56:50 (12.8 MB/s) - ‘rtdetr_r50vd_6x_coco_from_paddle.pth’ saved [172373587/172373587]\n",
            "\n",
            "✅ Pretrained weights downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**IMPORTANT:** Ensure you have uploaded the VisDrone zip files to `/content/` before running the next cell."
      ],
      "metadata": {
        "id": "upload_reminder"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. Unzip VisDrone Datasets\n",
        "import zipfile\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "# --- IMPORTANT ---\n",
        "# --- Upload your VisDrone zip files to /content/ before running this cell ---\n",
        "# Expected files:\n",
        "# /content/VisDrone2019-DET-train.zip\n",
        "# /content/VisDrone2019-DET-val.zip\n",
        "# /content/VisDrone2019-DET-test-dev.zip\n",
        "# ---------------\n",
        "\n",
        "zip_files = {\n",
        "    \"/content/VisDrone2019-DET-train.zip\": \"/content/VisDrone2019-DET-train\",\n",
        "    \"/content/VisDrone2019-DET-val.zip\": \"/content/VisDrone2019-DET-val\",\n",
        "    \"/content/VisDrone2019-DET-test-dev.zip\": \"/content/VisDrone2019-DET-test-dev\"\n",
        "}\n",
        "\n",
        "missing_files = [zip_path for zip_path in zip_files if not os.path.exists(zip_path)]\n",
        "if missing_files:\n",
        "    print(\"🚨 ERROR: The following zip files are missing in /content/:\")\n",
        "    for f in missing_files:\n",
        "        print(f\"- {f}\")\n",
        "    print(\"🛑 Please upload the files and try again.\")\n",
        "else:\n",
        "    print(\"👍 Found all necessary zip files.\")\n",
        "    start_time = time.time()\n",
        "    for zip_path, extract_path in zip_files.items():\n",
        "        print(f\"📦 Unzipping {os.path.basename(zip_path)}...\")\n",
        "        try:\n",
        "            # Ensure target directory exists and is empty\n",
        "            if os.path.exists(extract_path):\n",
        "                shutil.rmtree(extract_path)\n",
        "            os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_path)\n",
        "            print(f\"✅ Extracted to: {extract_path}\")\n",
        "        except zipfile.BadZipFile:\n",
        "            print(f\"❌ Error: {zip_path} is not a valid zip file.\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ An error occurred during extraction: {e}\")\n",
        "    end_time = time.time()\n",
        "    print(f\"\\n⏱️ Unzipping completed in {end_time - start_time:.2f} seconds.\")"
      ],
      "metadata": {
        "id": "unzip_datasets",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4b49ae-4c0a-4e2b-db7e-297181f1739f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "👍 Found all necessary zip files.\n",
            "📦 Unzipping VisDrone2019-DET-train.zip...\n",
            "✅ Extracted to: /content/VisDrone2019-DET-train\n",
            "📦 Unzipping VisDrone2019-DET-val.zip...\n",
            "✅ Extracted to: /content/VisDrone2019-DET-val\n",
            "📦 Unzipping VisDrone2019-DET-test-dev.zip...\n",
            "✅ Extracted to: /content/VisDrone2019-DET-test-dev\n",
            "\n",
            "⏱️ Unzipping completed in 9.04 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Clean Up Dataset Structure\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def clean_visdrone_folder(folder_path, expected_name):\n",
        "    \"\"\"Checks for nested folders and removes extra files.\"\"\"\n",
        "    print(f\"\\n🧹 Cleaning up {folder_path}...\")\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"⚠️ Folder not found: {folder_path}\")\n",
        "        return\n",
        "\n",
        "    # Handle potential nesting (e.g., VisDrone2019-DET-train/VisDrone2019-DET-train/)\n",
        "    sub_items = os.listdir(folder_path)\n",
        "    nested_path = os.path.join(folder_path, expected_name)\n",
        "\n",
        "    if len(sub_items) == 1 and os.path.isdir(nested_path):\n",
        "        print(f\"  -> Detected nested folder: {nested_path}. Moving contents up.\")\n",
        "        for item in os.listdir(nested_path):\n",
        "            try:\n",
        "                shutil.move(os.path.join(nested_path, item), folder_path)\n",
        "            except Exception as e:\n",
        "                 print(f\"  -> Error moving {item}: {e}. It might already exist.\")\n",
        "                 # If move fails because it exists, try removing the source if it's a dir\n",
        "                 if os.path.isdir(os.path.join(nested_path, item)):\n",
        "                     try:\n",
        "                         shutil.rmtree(os.path.join(nested_path, item))\n",
        "                     except: pass # Ignore removal error\n",
        "                 elif os.path.isfile(os.path.join(nested_path, item)):\n",
        "                     try:\n",
        "                         os.remove(os.path.join(nested_path, item))\n",
        "                     except: pass # Ignore removal error\n",
        "\n",
        "        # Attempt to remove the now empty nested directory\n",
        "        try:\n",
        "            os.rmdir(nested_path) # Use os.rmdir for potentially empty dir first\n",
        "            print(f\"  -> Removed empty nested folder.\")\n",
        "        except OSError:\n",
        "           try:\n",
        "               shutil.rmtree(nested_path) # Force remove if not empty\n",
        "               print(f\"  -> Force removed nested folder structure.\")\n",
        "           except OSError as e:\n",
        "               print(f\"  -> Warning: Could not remove nested folder {nested_path}: {e}\")\n",
        "               if os.path.exists(nested_path):\n",
        "                   print(f\"  -> Contents of nested folder: {os.listdir(nested_path)}\")\n",
        "\n",
        "    # Remove specific unwanted files/folders\n",
        "    items_to_remove = ['.DS_Store', '__MACOSX'] # Add other unwanted items if needed\n",
        "    for item in os.listdir(folder_path):\n",
        "        item_path = os.path.join(folder_path, item)\n",
        "        if item in items_to_remove or item.endswith('.zip'):\n",
        "             try:\n",
        "                if os.path.isfile(item_path):\n",
        "                    os.remove(item_path)\n",
        "                    print(f\"  -> Removed file: {item}\")\n",
        "                elif os.path.isdir(item_path):\n",
        "                    shutil.rmtree(item_path)\n",
        "                    print(f\"  -> Removed directory: {item}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"  -> Error removing {item}: {e}\")\n",
        "\n",
        "    print(f\"✅ Cleanup finished for {folder_path}.\")\n",
        "    if os.path.exists(folder_path):\n",
        "      print(f\"   Contents: {os.listdir(folder_path)}\")\n",
        "    else:\n",
        "      print(f\"   Folder {folder_path} no longer exists after cleanup?\")\n",
        "\n",
        "\n",
        "# Clean each dataset directory\n",
        "clean_visdrone_folder(\"/content/VisDrone2019-DET-train\", \"VisDrone2019-DET-train\")\n",
        "clean_visdrone_folder(\"/content/VisDrone2019-DET-val\", \"VisDrone2019-DET-val\")\n",
        "clean_visdrone_folder(\"/content/VisDrone2019-DET-test-dev\", \"VisDrone2019-DET-test-dev\")\n",
        "\n",
        "# Final check\n",
        "print(\"\\n📁 Final Data Structure Check:\")\n",
        "for folder in [\"/content/VisDrone2019-DET-train\", \"/content/VisDrone2019-DET-val\", \"/content/VisDrone2019-DET-test-dev\"]:\n",
        "    if os.path.exists(folder):\n",
        "        print(f\"  {folder}:\")\n",
        "        for sub in os.listdir(folder):\n",
        "            print(f\"    - {sub}\")\n",
        "        # Verify key subfolders\n",
        "        if not os.path.exists(os.path.join(folder, \"images\")):\n",
        "             print(f\"    ⚠️ Missing 'images' folder in {folder}\")\n",
        "        if not os.path.exists(os.path.join(folder, \"annotations\")):\n",
        "             print(f\"    ⚠️ Missing 'annotations' folder in {folder}\")\n",
        "    else:\n",
        "        print(f\"  {folder}: ❌ NOT FOUND\")"
      ],
      "metadata": {
        "id": "clean_structure",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7103f08-bbea-4ab1-804b-a7940b73057f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧹 Cleaning up /content/VisDrone2019-DET-train...\n",
            "✅ Cleanup finished for /content/VisDrone2019-DET-train.\n",
            "   Contents: ['images', 'annotations']\n",
            "\n",
            "🧹 Cleaning up /content/VisDrone2019-DET-val...\n",
            "✅ Cleanup finished for /content/VisDrone2019-DET-val.\n",
            "   Contents: ['images', 'annotations']\n",
            "\n",
            "🧹 Cleaning up /content/VisDrone2019-DET-test-dev...\n",
            "✅ Cleanup finished for /content/VisDrone2019-DET-test-dev.\n",
            "   Contents: ['images', 'annotations']\n",
            "\n",
            "📁 Final Data Structure Check:\n",
            "  /content/VisDrone2019-DET-train:\n",
            "    - images\n",
            "    - annotations\n",
            "  /content/VisDrone2019-DET-val:\n",
            "    - images\n",
            "    - annotations\n",
            "  /content/VisDrone2019-DET-test-dev:\n",
            "    - images\n",
            "    - annotations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 7. Convert VisDrone Annotations to COCO Format\n",
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm # Use notebook version for better Colab display\n",
        "import cv2 # Import OpenCV to get image dimensions\n",
        "import os\n",
        "\n",
        "def visdrone_to_coco(images_dir, annotations_dir, output_json):\n",
        "    images_path = Path(images_dir)\n",
        "    annotations_path = Path(annotations_dir)\n",
        "    output_file = Path(output_json)\n",
        "\n",
        "    print(f\"\\n🔄 Converting {images_path.parent.name} to COCO format...\")\n",
        "    print(f\"   Images: {images_dir}\")\n",
        "    print(f\"   Annotations: {annotations_dir}\")\n",
        "    print(f\"   Output: {output_json}\")\n",
        "\n",
        "    coco = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": [\n",
        "            # COCO format typically starts IDs from 1, but VisDrone uses 0-11.\n",
        "            # We keep the VisDrone IDs but map them. RT-DETR handles this.\n",
        "            # Class IDs MUST match the 'num_classes' in the model config later.\n",
        "            # We target the 10 main classes (1-10).\n",
        "            {\"id\": 0, \"name\": \"ignored regions\"}, # Often ignored in training\n",
        "            {\"id\": 1, \"name\": \"pedestrian\"},\n",
        "            {\"id\": 2, \"name\": \"people\"}, # Often grouped with pedestrian\n",
        "            {\"id\": 3, \"name\": \"bicycle\"},\n",
        "            {\"id\": 4, \"name\": \"car\"},\n",
        "            {\"id\": 5, \"name\": \"van\"},\n",
        "            {\"id\": 6, \"name\": \"truck\"},\n",
        "            {\"id\": 7, \"name\": \"tricycle\"},\n",
        "            {\"id\": 8, \"name\": \"awning-tricycle\"},\n",
        "            {\"id\": 9, \"name\": \"bus\"},\n",
        "            {\"id\": 10, \"name\": \"motor\"},\n",
        "            {\"id\": 11, \"name\": \"others\"} # Often ignored\n",
        "        ]\n",
        "        # It's common to remap VisDrone categories slightly for standard detection tasks\n",
        "        # E.g., map 'people' (2) -> 'pedestrian' (1), map 'ignored'(0) and 'others'(11) to a background/ignore class.\n",
        "        # For simplicity here, we keep the original 12 categories. The model config's `num_classes=10`\n",
        "        # implies it will focus on classes 1-10.\n",
        "    }\n",
        "\n",
        "    # VisDrone category IDs we care about (assuming 10 main classes)\n",
        "    valid_category_ids = set(range(1, 11)) # 1 to 10\n",
        "\n",
        "    annotation_id = 1\n",
        "    image_id_map = {} # Map image filenames to COCO image IDs\n",
        "\n",
        "    image_files = sorted(list(images_path.glob('*.jpg')))\n",
        "    if not image_files:\n",
        "        print(f\"❌ No JPG images found in {images_dir}. Please check the path.\")\n",
        "        return\n",
        "\n",
        "    print(f\"   Found {len(image_files)} images.\")\n",
        "\n",
        "    current_image_id = 1\n",
        "    for image_path in tqdm(image_files, desc=f\"Processing {images_path.parent.name}\"):\n",
        "        # Get image dimensions using OpenCV\n",
        "        try:\n",
        "            img = cv2.imread(str(image_path))\n",
        "            if img is None:\n",
        "                print(f\"   ⚠️ Warning: Could not read image {image_path.name}. Skipping.\")\n",
        "                continue\n",
        "            height, width, _ = img.shape\n",
        "        except Exception as e:\n",
        "            print(f\"   ⚠️ Warning: Error reading {image_path.name}: {e}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        image_info = {\n",
        "            \"file_name\": image_path.name,\n",
        "            \"id\": current_image_id,\n",
        "            \"height\": height,\n",
        "            \"width\": width\n",
        "        }\n",
        "        coco[\"images\"].append(image_info)\n",
        "        image_id_map[image_path.name] = current_image_id\n",
        "\n",
        "        ann_file = annotations_path / image_path.with_suffix('.txt').name\n",
        "        if ann_file.exists():\n",
        "            with open(ann_file, 'r') as f:\n",
        "                for line in f.readlines():\n",
        "                    try:\n",
        "                        # <bbox_left>,<bbox_top>,<width>,<height>,<score>,<category>,<truncation>,<occlusion>\n",
        "                        parts = list(map(int, line.strip().split(',')[:8]))\n",
        "                        x, y, w, h, score, cat_id, trunc, occ = parts\n",
        "\n",
        "                        # Skip categories we decided to ignore (like 0: ignored, 11: others)\n",
        "                        # Also skip score 0 if desired (often means ignore)\n",
        "                        if cat_id not in valid_category_ids or score == 0:\n",
        "                           continue\n",
        "\n",
        "                        # Basic sanity check for bounding boxes\n",
        "                        if w <= 0 or h <= 0:\n",
        "                            # print(f\"   ⚠️ Invalid bbox dims (w={w}, h={h}) in {ann_file.name}. Skipping annotation.\")\n",
        "                            continue\n",
        "                        # Ensure bbox is within image bounds (optional, but good practice)\n",
        "                        # x = max(0, x)\n",
        "                        # y = max(0, y)\n",
        "                        # w = min(width - x, w)\n",
        "                        # h = min(height - y, h)\n",
        "                        # if w <= 0 or h <= 0: continue # Skip if adjusted dims are invalid\n",
        "\n",
        "                        coco[\"annotations\"].append({\n",
        "                            \"id\": annotation_id,\n",
        "                            \"image_id\": current_image_id, # Use the mapped ID\n",
        "                            \"category_id\": cat_id,        # Use original VisDrone cat ID\n",
        "                            \"bbox\": [x, y, w, h],         # COCO format: [top_left_x, top_left_y, width, height]\n",
        "                            \"area\": float(w * h),\n",
        "                            \"iscrowd\": 0,                 # VisDrone doesn't typically use 'iscrowd'\n",
        "                            # You could add truncation/occlusion here if needed by your model/eval\n",
        "                            # \"truncation\": trunc,\n",
        "                            # \"occlusion\": occ\n",
        "                        })\n",
        "                        annotation_id += 1\n",
        "                    except ValueError:\n",
        "                        print(f\"   ⚠️ Warning: Could not parse line in {ann_file.name}: '{line.strip()}'. Skipping.\")\n",
        "                    except Exception as e:\n",
        "                         print(f\"   ⚠️ Error processing line in {ann_file.name}: {e}. Skipping annotation.\")\n",
        "\n",
        "        else:\n",
        "            # print(f\"   Note: No annotation file found for {image_path.name}\") # Optional: report missing annotations\n",
        "            pass\n",
        "\n",
        "        current_image_id += 1 # Increment for the next image\n",
        "\n",
        "    print(f\"   Processed {len(coco['images'])} images and {len(coco['annotations'])} annotations.\")\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(coco, f, indent=4)\n",
        "    print(f\"✅ Saved COCO annotations to: {output_file}\\n\")\n",
        "\n",
        "# Define dataset splits and paths\n",
        "# Ensure these paths match the output of the unzipping/cleanup step\n",
        "splits = {\n",
        "    \"train\": {\n",
        "        \"images\": \"/content/VisDrone2019-DET-train/images\",\n",
        "        \"annotations\": \"/content/VisDrone2019-DET-train/annotations\",\n",
        "        \"output\": \"/content/visdrone_train_coco.json\" # Save JSON in /content/\n",
        "    },\n",
        "    \"val\": {\n",
        "        \"images\": \"/content/VisDrone2019-DET-val/images\",\n",
        "        \"annotations\": \"/content/VisDrone2019-DET-val/annotations\",\n",
        "        \"output\": \"/content/visdrone_val_coco.json\"\n",
        "    },\n",
        "    \"test\": { # Using test-dev for testing/inference later\n",
        "        \"images\": \"/content/VisDrone2019-DET-test-dev/images\",\n",
        "        \"annotations\": \"/content/VisDrone2019-DET-test-dev/annotations\", # VisDrone test annotations might be empty or dummy\n",
        "        \"output\": \"/content/visdrone_test_coco.json\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Run conversion for all splits\n",
        "conversion_successful = True\n",
        "for split_name, paths in splits.items():\n",
        "    if not os.path.exists(paths[\"images\"]):\n",
        "        print(f\"🚨 ERROR: Image directory not found for '{split_name}': {paths['images']}\")\n",
        "        conversion_successful = False\n",
        "    if not os.path.exists(paths[\"annotations\"]):\n",
        "         print(f\"🚨 ERROR: Annotation directory not found for '{split_name}': {paths['annotations']}\")\n",
        "         # Allow continuing for 'test' split as annotations might be absent\n",
        "         if split_name != 'test':\n",
        "              conversion_successful = False\n",
        "\n",
        "if conversion_successful:\n",
        "    for split_name, paths in splits.items():\n",
        "        visdrone_to_coco(paths[\"images\"], paths[\"annotations\"], paths[\"output\"])\n",
        "    print(\"✅ All conversions attempted.\")\n",
        "else:\n",
        "    print(\"🛑 Conversion skipped due to missing directories. Please check the paths and the output of Step 6.\")"
      ],
      "metadata": {
        "id": "convert_to_coco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620,
          "referenced_widgets": [
            "ad9d828e4092455bb209015290d82a43",
            "ed572fbbc10b4af78ee45ba397722355",
            "70bd4b1c62e34ac3ad9da876e8510f5b",
            "99bd57ab52f04992bcaef8f161ef566d",
            "9bd0264f0dfb4fd7aa3beddb817b1668",
            "08389032e9a943a5b193e2349f3829e1",
            "e1096b3ea5794a3c8147935ac87ed2dd",
            "6c410411d5a04a23877639cd59404c5b",
            "7a1f24ce331a49aba679526b117f962f",
            "1fbc0898d56a41c0813aa75fbdf59d8d",
            "82b23fd2d3b64968af909a662b35895c",
            "c93921d596e14dea85a6add6a12f5dc4",
            "c581ee6853154e168ca598f4b4d65790",
            "a869fec5d6e04230b3976f558044db91",
            "65ddd14b4e6f455c934e78cb3e4298c3",
            "ad31c0dbc5a3467e964cb5168491fd6e",
            "2ba62ac867f8455db66fe6f25ed15a23",
            "f0eac5ba26184c12a868059e5885b876",
            "2b05b71689104876a508f64a39c766da",
            "d53fe952e51d4bf0a2db488b17045835",
            "9539133b3fae49a48ea4f576ee88d7a0",
            "ccc632bfc277493c9fd5c14271594688",
            "ec701ed5da0d40d6bc2ac16770e5b178",
            "a6852728a3e84af7b33b8a27ce0744a2",
            "c6413a25afeb411a945f6eb12085b28a",
            "585c14ce5c2a482ba443bd5de91b9bc5",
            "2b78686e4ac14efdbd6ad0581a5fa095",
            "6d48527ceb8b4f678c57a31359eaa5b4",
            "c2f94f92dfa44f33bcd96490dc3d2cab",
            "0bad5c9fb34441f79407bc465be6ac1d",
            "28606494b0274f2e94b2604692259221",
            "549da782432f4abe9ef9dfeaebb301e2",
            "5e38d68183574d708c8ac7f8acab2d39"
          ]
        },
        "outputId": "8de5472e-9935-4136-eafa-df7310bc0b41"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Converting VisDrone2019-DET-train to COCO format...\n",
            "   Images: /content/VisDrone2019-DET-train/images\n",
            "   Annotations: /content/VisDrone2019-DET-train/annotations\n",
            "   Output: /content/visdrone_train_coco.json\n",
            "   Found 6471 images.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing VisDrone2019-DET-train:   0%|          | 0/6471 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad9d828e4092455bb209015290d82a43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Processed 6471 images and 343204 annotations.\n",
            "✅ Saved COCO annotations to: /content/visdrone_train_coco.json\n",
            "\n",
            "\n",
            "🔄 Converting VisDrone2019-DET-val to COCO format...\n",
            "   Images: /content/VisDrone2019-DET-val/images\n",
            "   Annotations: /content/VisDrone2019-DET-val/annotations\n",
            "   Output: /content/visdrone_val_coco.json\n",
            "   Found 548 images.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing VisDrone2019-DET-val:   0%|          | 0/548 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c93921d596e14dea85a6add6a12f5dc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Processed 548 images and 38759 annotations.\n",
            "✅ Saved COCO annotations to: /content/visdrone_val_coco.json\n",
            "\n",
            "\n",
            "🔄 Converting VisDrone2019-DET-test-dev to COCO format...\n",
            "   Images: /content/VisDrone2019-DET-test-dev/images\n",
            "   Annotations: /content/VisDrone2019-DET-test-dev/annotations\n",
            "   Output: /content/visdrone_test_coco.json\n",
            "   Found 1610 images.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing VisDrone2019-DET-test-dev:   0%|          | 0/1610 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec701ed5da0d40d6bc2ac16770e5b178"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Processed 1610 images and 75102 annotations.\n",
            "✅ Saved COCO annotations to: /content/visdrone_test_coco.json\n",
            "\n",
            "✅ All conversions attempted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 8. Create Dataset Configuration File\n",
        "import os\n",
        "\n",
        "# Create the directory structure within the rtdetrv2_pytorch folder\n",
        "# This is where the training script expects config files relative to its location\n",
        "dataset_config_dir = \"/content/RT-DETR/rtdetrv2_pytorch/configs/datasets\"\n",
        "os.makedirs(dataset_config_dir, exist_ok=True)\n",
        "\n",
        "yaml_path = os.path.join(dataset_config_dir, 'visdrone_coco.yaml')\n",
        "\n",
        "# YAML content using the paths where we saved the COCO JSON files\n",
        "# and the absolute paths to the image directories\n",
        "yaml_content = f\"\"\"\n",
        "# Dataset specific configurations\n",
        "dataset_type: coco # Specify the dataset type reader\n",
        "train_dataset:\n",
        "  name: coco_train # Can be any name\n",
        "  img_folder: /content/VisDrone2019-DET-train/images # Absolute path to train images\n",
        "  ann_file: /content/visdrone_train_coco.json      # Absolute path to train COCO json\n",
        "  transforms:\n",
        "\n",
        "val_dataset:\n",
        "  name: coco_val\n",
        "  img_folder: /content/VisDrone2019-DET-val/images   # Absolute path to val images\n",
        "  ann_file: /content/visdrone_val_coco.json        # Absolute path to val COCO json\n",
        "  transforms:\n",
        "\n",
        "test_dataset: # Optional: if you want to run evaluation on the test set later\n",
        "  name: coco_test\n",
        "  img_folder: /content/VisDrone2019-DET-test-dev/images # Absolute path to test images\n",
        "  ann_file: /content/visdrone_test_coco.json       # Absolute path to test COCO json\n",
        "  transforms:\n",
        "\n",
        "# Define label map if needed, otherwise defaults might be used\n",
        "# For VisDrone (10 classes + background), this might not be strictly necessary if num_classes is set correctly\n",
        "# label_map: ...\n",
        "num_classes: 10 # IMPORTANT: Number of main VisDrone classes (1-10)\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to the file\n",
        "with open(yaml_path, 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(f\"✅ Created Dataset Config: {yaml_path}\")\n",
        "# Verify creation\n",
        "!ls -l /content/RT-DETR/rtdetrv2_pytorch/configs/datasets/"
      ],
      "metadata": {
        "id": "create_dataset_config",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0eda40-72ff-47b8-bc0f-d45255f1e4e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created Dataset Config: /content/RT-DETR/rtdetrv2_pytorch/configs/datasets/visdrone_coco.yaml\n",
            "total 4\n",
            "-rw-r--r-- 1 root root 1080 Apr  1 09:01 visdrone_coco.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 9. Create Training Configuration File (Consolidated v9 - Default Matcher Name)\n",
        "import os\n",
        "\n",
        "# Create the directory structure within the rtdetrv2_pytorch folder\n",
        "model_config_dir = \"/content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr\"\n",
        "os.makedirs(model_config_dir, exist_ok=True)\n",
        "\n",
        "# Use a new distinct name\n",
        "config_path = os.path.join(model_config_dir, \"rtdetr_r50vd_6x_visdrone_consolidated_v9.yml\")\n",
        "\n",
        "# Define the YAML structure template\n",
        "# Define HungarianMatcher component using its default name\n",
        "visdrone_config_template = \"\"\"\n",
        "# --- Consolidated Config for VisDrone (v9 - Default Matcher Name) ---\n",
        "\n",
        "task: detection\n",
        "\n",
        "# --- Runtime Settings ---\n",
        "use_ema: true\n",
        "ema_decay: 0.9999\n",
        "# epoches: 72\n",
        "# snapshot_epoch: 1\n",
        "# log_iter: 20\n",
        "# save_dir: ./output\n",
        "# sync_bn: false\n",
        "\n",
        "# --- Dataset Settings ---\n",
        "dataset_type: coco\n",
        "train_dataset:\n",
        "  name: coco_train\n",
        "  img_folder: /content/VisDrone2019-DET-train/images\n",
        "  ann_file: /content/visdrone_train_coco.json\n",
        "val_dataset:\n",
        "  name: coco_val\n",
        "  img_folder: /content/VisDrone2019-DET-val/images\n",
        "  ann_file: /content/visdrone_val_coco.json\n",
        "\n",
        "num_classes: {num_classes_placeholder}\n",
        "\n",
        "# --- DataLoader Settings ---\n",
        "train_dataloader:\n",
        "  batch_size: 8\n",
        "  num_workers: 4\n",
        "  shuffle: True\n",
        "val_dataloader:\n",
        "  batch_size: 8\n",
        "  num_workers: 4\n",
        "  shuffle: False\n",
        "\n",
        "# --- Linking Model Components ---\n",
        "model: RTDETR\n",
        "criterion: RTDETRCriterion\n",
        "postprocessor: RTDETRPostProcessor\n",
        "\n",
        "# --- Component Definitions ---\n",
        "use_focal_loss: {use_focal_loss_placeholder}\n",
        "eval_spatial_size: [640, 640]\n",
        "\n",
        "RTDETR:\n",
        "  backbone: PResNet\n",
        "  encoder: HybridEncoder\n",
        "  decoder: RTDETRTransformer\n",
        "\n",
        "PResNet:\n",
        "  depth: 50\n",
        "  variant: d\n",
        "  freeze_at: 0\n",
        "  return_idx: [1, 2, 3]\n",
        "  num_stages: 4\n",
        "  freeze_norm: True\n",
        "  pretrained: True\n",
        "\n",
        "HybridEncoder:\n",
        "  in_channels: [512, 1024, 2048]\n",
        "  feat_strides: [8, 16, 32]\n",
        "  hidden_dim: 256\n",
        "  use_encoder_idx: [2]\n",
        "  num_encoder_layers: 1\n",
        "  nhead: 8\n",
        "  dim_feedforward: 1024\n",
        "  dropout: 0.\n",
        "  enc_act: 'gelu'\n",
        "  expansion: 1.0\n",
        "  depth_mult: 1.0\n",
        "  act: 'silu'\n",
        "\n",
        "RTDETRTransformer:\n",
        "  num_classes: {num_classes_placeholder}\n",
        "  feat_channels: [256, 256, 256]\n",
        "  feat_strides: [8, 16, 32]\n",
        "  hidden_dim: 256\n",
        "  num_levels: 3\n",
        "  num_layers: 6\n",
        "  num_queries: 300\n",
        "  num_denoising: 100\n",
        "  label_noise_ratio: 0.5\n",
        "  box_noise_scale: 1.0\n",
        "  eval_idx: -1\n",
        "\n",
        "RTDETRPostProcessor:\n",
        "  num_classes: {num_classes_placeholder}\n",
        "  num_top_queries: 300\n",
        "\n",
        "# --- Define the Matcher Component using its CLASS NAME as the key ---\n",
        "# This mirrors the structure seen in the default included rtdetr_r50vd.yml\n",
        "HungarianMatcher: # Use the actual class name as the component key\n",
        "  # 'type' key might not be needed if the key matches the class name\n",
        "  cost_class: 2\n",
        "  cost_bbox: 5\n",
        "  cost_giou: 2\n",
        "\n",
        "RTDETRCriterion:\n",
        "  num_classes: {num_classes_placeholder}\n",
        "  use_focal_loss: {use_focal_loss_placeholder}\n",
        "  weight_dict: {{loss_vfl: 1, loss_bbox: 5, loss_giou: 2}}\n",
        "  losses: ['vfl', 'boxes']\n",
        "  alpha: 0.75\n",
        "  gamma: 2.0\n",
        "  matcher: HungarianMatcher # Reference the component defined above by its name (which is the class name)\n",
        "\n",
        "# --- Optimizer Settings ---\n",
        "optimizer:\n",
        "  type: AdamW\n",
        "  lr: 0.0001\n",
        "  weight_decay: 0.0001\n",
        "\n",
        "lr_scheduler:\n",
        "  type: MultiStep\n",
        "  milestones: [60, 68]\n",
        "  gamma: 0.1\n",
        "\n",
        "# --- Training Overrides ---\n",
        "output_dir: output/rtdetr_r50vd_6x_visdrone_consolidated_v9\n",
        "\"\"\"\n",
        "\n",
        "# Write the config file using .format() to substitute the placeholders\n",
        "with open(config_path, \"w\") as f:\n",
        "    f.write(visdrone_config_template.format(\n",
        "        num_classes_placeholder=10,\n",
        "        use_focal_loss_placeholder=True\n",
        "    ))\n",
        "print(f\"✅ Created Consolidated Config (v9): {config_path}\")\n",
        "\n",
        "# Verify the created file\n",
        "print(f\"\\n--- Verifying created config: {config_path} ---\")\n",
        "!cat {config_path}\n",
        "print(\"--- End config verification ---\")\n",
        "\n",
        "# IMPORTANT: Update the training command\n",
        "print(\"\\n❗ Remember to update the training command in Cell 11 to use:\")\n",
        "print(f\"   -c {config_path}\")"
      ],
      "metadata": {
        "id": "create_training_config",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "992f1a1b-fbc4-40c1-c4c1-16abcc2a6ef7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created Consolidated Config (v9): /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_visdrone_consolidated_v9.yml\n",
            "\n",
            "--- Verifying created config: /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_visdrone_consolidated_v9.yml ---\n",
            "\n",
            "# --- Consolidated Config for VisDrone (v9 - Default Matcher Name) ---\n",
            "\n",
            "task: detection\n",
            "\n",
            "# --- Runtime Settings ---\n",
            "use_ema: true\n",
            "ema_decay: 0.9999\n",
            "# epoches: 72\n",
            "# snapshot_epoch: 1\n",
            "# log_iter: 20\n",
            "# save_dir: ./output\n",
            "# sync_bn: false\n",
            "\n",
            "# --- Dataset Settings ---\n",
            "dataset_type: coco\n",
            "train_dataset:\n",
            "  name: coco_train\n",
            "  img_folder: /content/VisDrone2019-DET-train/images\n",
            "  ann_file: /content/visdrone_train_coco.json\n",
            "val_dataset:\n",
            "  name: coco_val\n",
            "  img_folder: /content/VisDrone2019-DET-val/images\n",
            "  ann_file: /content/visdrone_val_coco.json\n",
            "\n",
            "num_classes: 10\n",
            "\n",
            "# --- DataLoader Settings ---\n",
            "train_dataloader:\n",
            "  batch_size: 8\n",
            "  num_workers: 4\n",
            "  shuffle: True\n",
            "val_dataloader:\n",
            "  batch_size: 8\n",
            "  num_workers: 4\n",
            "  shuffle: False\n",
            "\n",
            "# --- Linking Model Components ---\n",
            "model: RTDETR\n",
            "criterion: RTDETRCriterion\n",
            "postprocessor: RTDETRPostProcessor\n",
            "\n",
            "# --- Component Definitions ---\n",
            "use_focal_loss: True\n",
            "eval_spatial_size: [640, 640]\n",
            "\n",
            "RTDETR:\n",
            "  backbone: PResNet\n",
            "  encoder: HybridEncoder\n",
            "  decoder: RTDETRTransformer\n",
            "\n",
            "PResNet:\n",
            "  depth: 50\n",
            "  variant: d\n",
            "  freeze_at: 0\n",
            "  return_idx: [1, 2, 3]\n",
            "  num_stages: 4\n",
            "  freeze_norm: True\n",
            "  pretrained: True\n",
            "\n",
            "HybridEncoder:\n",
            "  in_channels: [512, 1024, 2048]\n",
            "  feat_strides: [8, 16, 32]\n",
            "  hidden_dim: 256\n",
            "  use_encoder_idx: [2]\n",
            "  num_encoder_layers: 1\n",
            "  nhead: 8\n",
            "  dim_feedforward: 1024\n",
            "  dropout: 0.\n",
            "  enc_act: 'gelu'\n",
            "  expansion: 1.0\n",
            "  depth_mult: 1.0\n",
            "  act: 'silu'\n",
            "\n",
            "RTDETRTransformer:\n",
            "  num_classes: 10\n",
            "  feat_channels: [256, 256, 256]\n",
            "  feat_strides: [8, 16, 32]\n",
            "  hidden_dim: 256\n",
            "  num_levels: 3\n",
            "  num_layers: 6\n",
            "  num_queries: 300\n",
            "  num_denoising: 100\n",
            "  label_noise_ratio: 0.5\n",
            "  box_noise_scale: 1.0\n",
            "  eval_idx: -1\n",
            "\n",
            "RTDETRPostProcessor:\n",
            "  num_classes: 10\n",
            "  num_top_queries: 300\n",
            "\n",
            "# --- Define the Matcher Component using its CLASS NAME as the key ---\n",
            "# This mirrors the structure seen in the default included rtdetr_r50vd.yml\n",
            "HungarianMatcher: # Use the actual class name as the component key\n",
            "  # 'type' key might not be needed if the key matches the class name\n",
            "  cost_class: 2\n",
            "  cost_bbox: 5\n",
            "  cost_giou: 2\n",
            "\n",
            "RTDETRCriterion:\n",
            "  num_classes: 10\n",
            "  use_focal_loss: True\n",
            "  weight_dict: {loss_vfl: 1, loss_bbox: 5, loss_giou: 2}\n",
            "  losses: ['vfl', 'boxes']\n",
            "  alpha: 0.75\n",
            "  gamma: 2.0\n",
            "  matcher: HungarianMatcher # Reference the component defined above by its name (which is the class name)\n",
            "\n",
            "# --- Optimizer Settings ---\n",
            "optimizer:\n",
            "  type: AdamW\n",
            "  lr: 0.0001\n",
            "  weight_decay: 0.0001\n",
            "\n",
            "lr_scheduler:\n",
            "  type: MultiStep\n",
            "  milestones: [60, 68]\n",
            "  gamma: 0.1\n",
            "\n",
            "# --- Training Overrides ---\n",
            "output_dir: output/rtdetr_r50vd_6x_visdrone_consolidated_v9\n",
            "--- End config verification ---\n",
            "\n",
            "❗ Remember to update the training command in Cell 11 to use:\n",
            "   -c /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_visdrone_consolidated_v9.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Restore Original coco_detection.yml (Optional)\n",
        "import os\n",
        "\n",
        "# Re-clone repo to a temp directory to get original file\n",
        "print(\"Cloning repo temporarily to get original dataset config...\")\n",
        "!git clone https://github.com/lyuwenyu/RT-DETR.git /tmp/RT-DETR-temp >> /dev/null # Suppress output\n",
        "\n",
        "original_file = '/tmp/RT-DETR-temp/rtdetrv2_pytorch/configs/dataset/coco_detection.yml'\n",
        "target_file = '/content/RT-DETR/rtdetrv2_pytorch/configs/dataset/coco_detection.yml'\n",
        "\n",
        "if os.path.exists(original_file):\n",
        "    try:\n",
        "        !cp {original_file} {target_file}\n",
        "        print(f\"✅ Restored {target_file} from repository.\")\n",
        "        # Clean up temp clone\n",
        "        !rm -rf /tmp/RT-DETR-temp\n",
        "        print(\"   Cleaned up temporary clone.\")\n",
        "        # Verify\n",
        "        print(\"\\n--- Verifying restored file content: ---\")\n",
        "        !cat {target_file}\n",
        "        print(\"\\n--- End verification ---\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error restoring file: {e}\")\n",
        "else:\n",
        "    print(\"❌ Could not find original file in temporary clone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msVhnTiBCxM3",
        "outputId": "ec53ea84-c7e1-4647-a2a2-7edc9bccd6fe"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repo temporarily to get original dataset config...\n",
            "Cloning into '/tmp/RT-DETR-temp'...\n",
            "remote: Enumerating objects: 1020, done.\u001b[K\n",
            "remote: Counting objects: 100% (220/220), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 1020 (delta 145), reused 120 (delta 120), pack-reused 800 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1020/1020), 626.16 KiB | 2.75 MiB/s, done.\n",
            "Resolving deltas: 100% (496/496), done.\n",
            "✅ Restored /content/RT-DETR/rtdetrv2_pytorch/configs/dataset/coco_detection.yml from repository.\n",
            "   Cleaned up temporary clone.\n",
            "\n",
            "--- Verifying restored file content: ---\n",
            "task: detection\n",
            "\n",
            "evaluator:\n",
            "  type: CocoEvaluator\n",
            "  iou_types: ['bbox', ]\n",
            "\n",
            "# num_classes: 365\n",
            "# remap_mscoco_category: False\n",
            "\n",
            "# num_classes: 91\n",
            "# remap_mscoco_category: False\n",
            "\n",
            "num_classes: 80\n",
            "remap_mscoco_category: True\n",
            "\n",
            "\n",
            "train_dataloader: \n",
            "  type: DataLoader\n",
            "  dataset: \n",
            "    type: CocoDetection\n",
            "    img_folder: ./dataset/coco/train2017/\n",
            "    ann_file: ./dataset/coco/annotations/instances_train2017.json\n",
            "    return_masks: False\n",
            "    transforms:\n",
            "      type: Compose\n",
            "      ops: ~\n",
            "  shuffle: True\n",
            "  num_workers: 4\n",
            "  drop_last: True \n",
            "  collate_fn:\n",
            "    type: BatchImageCollateFuncion\n",
            "\n",
            "\n",
            "val_dataloader:\n",
            "  type: DataLoader\n",
            "  dataset: \n",
            "    type: CocoDetection\n",
            "    img_folder: ./dataset/coco/val2017/\n",
            "    ann_file: ./dataset/coco/annotations/instances_val2017.json\n",
            "    return_masks: False\n",
            "    transforms:\n",
            "      type: Compose\n",
            "      ops: ~ \n",
            "  shuffle: False\n",
            "  num_workers: 4\n",
            "  drop_last: False\n",
            "  collate_fn:\n",
            "    type: BatchImageCollateFuncion\n",
            "\n",
            "--- End verification ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install ruamel.yaml dependency\n",
        "print(\"Installing ruamel.yaml...\")\n",
        "!pip install ruamel.yaml\n",
        "print(\"✅ ruamel.yaml installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWgYdaRhDVle",
        "outputId": "f8b67731-9116-4326-bb03-495507bd9041"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing ruamel.yaml...\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml\n",
            "Successfully installed ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12\n",
            "✅ ruamel.yaml installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Add/Override Dataset Settings in Main Config (rtdetr_r50vd_6x_coco.yml)\n",
        "import os\n",
        "from ruamel.yaml import YAML\n",
        "\n",
        "main_config_path = '/content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_coco.yml'\n",
        "print(f\"--- Adding/Overriding Dataset settings in: {main_config_path} ---\")\n",
        "\n",
        "yaml_loader = YAML()\n",
        "yaml_loader.preserve_quotes = True\n",
        "yaml_loader.indent(mapping=2, sequence=4, offset=2) # Adjust indent as needed\n",
        "\n",
        "try:\n",
        "    with open(main_config_path, 'r') as f:\n",
        "        main_config = yaml_loader.load(f)\n",
        "\n",
        "    # --- Define VisDrone Dataset Blocks ---\n",
        "    # These will override anything included from coco_detection.yml\n",
        "    visdrone_train_dataset = {\n",
        "        'name': 'visdrone_train',\n",
        "        'img_folder': '/content/VisDrone2019-DET-train/images',\n",
        "        'ann_file': '/content/visdrone_train_coco.json',\n",
        "        # Add 'transforms:' if needed, copying structure from default if available\n",
        "        # 'transforms': {}\n",
        "    }\n",
        "    visdrone_val_dataset = {\n",
        "        'name': 'visdrone_val',\n",
        "        'img_folder': '/content/VisDrone2019-DET-val/images',\n",
        "        'ann_file': '/content/visdrone_val_coco.json',\n",
        "        # 'transforms': {}\n",
        "    }\n",
        "    visdrone_test_dataset = {\n",
        "        'name': 'visdrone_test',\n",
        "        'img_folder': '/content/VisDrone2019-DET-test-dev/images',\n",
        "        'ann_file': '/content/visdrone_test_coco.json',\n",
        "        # 'transforms': {}\n",
        "    }\n",
        "\n",
        "    # --- Add/Update keys in the loaded config ---\n",
        "    print(\"  Updating num_classes...\")\n",
        "    main_config['num_classes'] = 10\n",
        "    print(\"  Updating train_dataset...\")\n",
        "    main_config['train_dataset'] = visdrone_train_dataset\n",
        "    print(\"  Updating val_dataset...\")\n",
        "    main_config['val_dataset'] = visdrone_val_dataset\n",
        "    print(\"  Updating test_dataset...\")\n",
        "    main_config['test_dataset'] = visdrone_test_dataset\n",
        "    print(\"  Ensuring output_dir is set for VisDrone...\")\n",
        "    main_config['output_dir'] = './output/rtdetr_r50vd_6x_visdrone' # Use the name we wanted\n",
        "\n",
        "\n",
        "    # --- Remove specific dataloader settings if they exist at top level ---\n",
        "    # These should ideally come from the included dataloader.yml\n",
        "    keys_to_remove = ['train_dataloader', 'val_dataloader']\n",
        "    for key in keys_to_remove:\n",
        "      if key in main_config:\n",
        "          print(f\"  Removing top-level '{key}' (should be included)\")\n",
        "          del main_config[key]\n",
        "\n",
        "\n",
        "    # --- Write the modified content back ---\n",
        "    with open(main_config_path, 'w') as f:\n",
        "        yaml_loader.dump(main_config, f)\n",
        "\n",
        "    print(f\"\\n✅ Successfully updated: {main_config_path}\")\n",
        "    print(\"\\n--- Verifying updated file content: ---\")\n",
        "    !cat {main_config_path}\n",
        "    print(\"\\n--- End verification ---\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error modifying {main_config_path}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74L4njCxC0bm",
        "outputId": "52bac482-88a1-4e03-e306-18bace06d275"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Adding/Overriding Dataset settings in: /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_coco.yml ---\n",
            "  Updating num_classes...\n",
            "  Updating train_dataset...\n",
            "  Updating val_dataset...\n",
            "  Updating test_dataset...\n",
            "  Ensuring output_dir is set for VisDrone...\n",
            "\n",
            "✅ Successfully updated: /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_coco.yml\n",
            "\n",
            "--- Verifying updated file content: ---\n",
            "__include__: ['../dataset/coco_detection.yml', '../runtime.yml', './include/dataloader.yml',\n",
            "  './include/optimizer.yml', './include/rtdetr_r50vd.yml']\n",
            "\n",
            "\n",
            "output_dir: ./output/rtdetr_r50vd_6x_visdrone\n",
            "\n",
            "\n",
            "\n",
            "num_classes: 10\n",
            "train_dataset:\n",
            "  name: visdrone_train\n",
            "  img_folder: /content/VisDrone2019-DET-train/images\n",
            "  ann_file: /content/visdrone_train_coco.json\n",
            "val_dataset:\n",
            "  name: visdrone_val\n",
            "  img_folder: /content/VisDrone2019-DET-val/images\n",
            "  ann_file: /content/visdrone_val_coco.json\n",
            "test_dataset:\n",
            "  name: visdrone_test\n",
            "  img_folder: /content/VisDrone2019-DET-test-dev/images\n",
            "  ann_file: /content/visdrone_test_coco.json\n",
            "\n",
            "--- End verification ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Modify Dataloader Dataset Settings in Main Config (rtdetr_r50vd_6x_coco.yml)\n",
        "import os\n",
        "from ruamel.yaml import YAML\n",
        "import sys # For error handling\n",
        "\n",
        "main_config_path = '/content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_coco.yml'\n",
        "print(f\"--- Modifying nested Dataset settings in: {main_config_path} ---\")\n",
        "\n",
        "yaml_loader = YAML()\n",
        "yaml_loader.preserve_quotes = True\n",
        "yaml_loader.indent(mapping=2, sequence=4, offset=2)\n",
        "\n",
        "try:\n",
        "    # Load the existing main config\n",
        "    with open(main_config_path, 'r') as f:\n",
        "        main_config = yaml_loader.load(f)\n",
        "\n",
        "    # --- Ensure top-level num_classes is correct ---\n",
        "    print(\"  Setting top-level num_classes...\")\n",
        "    main_config['num_classes'] = 10\n",
        "\n",
        "    # --- Define the VisDrone dataset configuration blocks ---\n",
        "    visdrone_train_dataset_def = {\n",
        "        'type': 'CocoDetection', # Assuming this is the correct type from includes\n",
        "        'img_folder': '/content/VisDrone2019-DET-train/images',\n",
        "        'ann_file': '/content/visdrone_train_coco.json',\n",
        "        'return_masks': False,\n",
        "        # If transforms were defined in the original dataloader include,\n",
        "        # they might still be inherited unless explicitly overridden here.\n",
        "        # We'll leave transforms out for now to inherit defaults.\n",
        "    }\n",
        "    visdrone_val_dataset_def = {\n",
        "        'type': 'CocoDetection',\n",
        "        'img_folder': '/content/VisDrone2019-DET-val/images',\n",
        "        'ann_file': '/content/visdrone_val_coco.json',\n",
        "        'return_masks': False,\n",
        "    }\n",
        "\n",
        "    # --- Explicitly define/override dataloader sections in the main config ---\n",
        "    # This ensures these definitions take precedence over includes.\n",
        "\n",
        "    print(\"  Defining/Overriding train_dataloader settings...\")\n",
        "    if 'train_dataloader' not in main_config:\n",
        "        main_config['train_dataloader'] = {} # Create block if missing\n",
        "    # Set the nested dataset key to our VisDrone definition\n",
        "    main_config['train_dataloader']['dataset'] = visdrone_train_dataset_def\n",
        "    # Set other dataloader params directly here if needed (overrides includes)\n",
        "    main_config['train_dataloader']['type'] = 'DataLoader' # Ensure type is set\n",
        "    main_config['train_dataloader']['shuffle'] = True\n",
        "    main_config['train_dataloader']['num_workers'] = 4\n",
        "    main_config['train_dataloader']['drop_last'] = True\n",
        "    # Use a default collate_fn type if needed, or let it inherit\n",
        "    # if 'collate_fn' not in main_config['train_dataloader']:\n",
        "    #     main_config['train_dataloader']['collate_fn'] = {'type': 'BatchImageCollateFuncion'}\n",
        "\n",
        "\n",
        "    print(\"  Defining/Overriding val_dataloader settings...\")\n",
        "    if 'val_dataloader' not in main_config:\n",
        "        main_config['val_dataloader'] = {}\n",
        "    main_config['val_dataloader']['dataset'] = visdrone_val_dataset_def\n",
        "    main_config['val_dataloader']['type'] = 'DataLoader'\n",
        "    main_config['val_dataloader']['shuffle'] = False\n",
        "    main_config['val_dataloader']['num_workers'] = 4 # Adjusted from default 8\n",
        "    main_config['val_dataloader']['drop_last'] = False\n",
        "    # if 'collate_fn' not in main_config['val_dataloader']:\n",
        "    #     main_config['val_dataloader']['collate_fn'] = {'type': 'BatchImageCollateFuncion'}\n",
        "\n",
        "\n",
        "    # --- Remove the separate top-level dataset definitions we added previously ---\n",
        "    print(\"  Removing previous top-level dataset definitions (if present)...\")\n",
        "    keys_to_remove = ['train_dataset', 'val_dataset', 'test_dataset']\n",
        "    for key in keys_to_remove:\n",
        "        if key in main_config:\n",
        "            try:\n",
        "                del main_config[key]\n",
        "                print(f\"    Removed '{key}'\")\n",
        "            except KeyError:\n",
        "                pass # Already removed or never existed\n",
        "\n",
        "    # --- Ensure output_dir is still correct ---\n",
        "    print(\"  Ensuring output_dir...\")\n",
        "    main_config['output_dir'] = './output/rtdetr_r50vd_6x_visdrone'\n",
        "\n",
        "    # --- Write the modified content back ---\n",
        "    with open(main_config_path, 'w') as f:\n",
        "        yaml_loader.dump(main_config, f)\n",
        "\n",
        "    print(f\"\\n✅ Successfully updated: {main_config_path}\")\n",
        "    print(\"\\n--- Verifying updated file content: ---\")\n",
        "    !cat {main_config_path}\n",
        "    print(\"\\n--- End verification ---\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error modifying {main_config_path}: {e}\", file=sys.stderr)\n",
        "    print(f\"   Type: {type(e).__name__}\", file=sys.stderr)\n",
        "    # Print existing content for debugging\n",
        "    try:\n",
        "        print(\"\\n--- Existing file content (on error): ---\", file=sys.stderr)\n",
        "        with open(main_config_path, 'r') as f_err:\n",
        "            print(f_err.read(), file=sys.stderr)\n",
        "        print(\"\\n--- End existing content ---\", file=sys.stderr)\n",
        "    except Exception as read_e:\n",
        "         print(f\"  (Could not read file content on error: {read_e})\", file=sys.stderr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upy7ewpEEBiQ",
        "outputId": "30269304-37f9-4744-e244-794340d921c0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Modifying nested Dataset settings in: /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_coco.yml ---\n",
            "  Setting top-level num_classes...\n",
            "  Defining/Overriding train_dataloader settings...\n",
            "  Defining/Overriding val_dataloader settings...\n",
            "  Removing previous top-level dataset definitions (if present)...\n",
            "    Removed 'train_dataset'\n",
            "    Removed 'val_dataset'\n",
            "    Removed 'test_dataset'\n",
            "  Ensuring output_dir...\n",
            "\n",
            "✅ Successfully updated: /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_coco.yml\n",
            "\n",
            "--- Verifying updated file content: ---\n",
            "__include__: ['../dataset/coco_detection.yml', '../runtime.yml', './include/dataloader.yml',\n",
            "  './include/optimizer.yml', './include/rtdetr_r50vd.yml']\n",
            "\n",
            "\n",
            "output_dir: ./output/rtdetr_r50vd_6x_visdrone\n",
            "\n",
            "\n",
            "\n",
            "num_classes: 10\n",
            "train_dataloader:\n",
            "  dataset:\n",
            "    type: CocoDetection\n",
            "    img_folder: /content/VisDrone2019-DET-train/images\n",
            "    ann_file: /content/visdrone_train_coco.json\n",
            "    return_masks: false\n",
            "  type: DataLoader\n",
            "  shuffle: true\n",
            "  num_workers: 4\n",
            "  drop_last: true\n",
            "val_dataloader:\n",
            "  dataset:\n",
            "    type: CocoDetection\n",
            "    img_folder: /content/VisDrone2019-DET-val/images\n",
            "    ann_file: /content/visdrone_val_coco.json\n",
            "    return_masks: false\n",
            "  type: DataLoader\n",
            "  shuffle: false\n",
            "  num_workers: 4\n",
            "  drop_last: false\n",
            "\n",
            "--- End verification ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Simplify Transforms in Included Config (./include/dataloader.yml)\n",
        "import os\n",
        "from ruamel.yaml import YAML\n",
        "import sys\n",
        "\n",
        "# Path to the included dataloader config\n",
        "include_config_path = '/content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/include/dataloader.yml'\n",
        "print(f\"--- Simplifying Transforms in included file: {include_config_path} ---\")\n",
        "\n",
        "# Ensure ruamel.yaml is installed (just in case)\n",
        "try:\n",
        "    from ruamel.yaml import YAML\n",
        "except ImportError:\n",
        "    print(\"Installing ruamel.yaml...\")\n",
        "    !pip install ruamel.yaml -q\n",
        "    from ruamel.yaml import YAML\n",
        "\n",
        "\n",
        "yaml_loader = YAML()\n",
        "yaml_loader.preserve_quotes = True\n",
        "# Adjust indentation based on the target file's style if needed\n",
        "yaml_loader.indent(mapping=2, sequence=4, offset=2)\n",
        "\n",
        "\n",
        "try:\n",
        "    # Load the included dataloader config\n",
        "    with open(include_config_path, 'r') as f:\n",
        "        include_config = yaml_loader.load(f)\n",
        "\n",
        "    # --- Define Simplified Transform Ops ---\n",
        "    simplified_train_transforms_ops = [\n",
        "        {'type': 'RandomHorizontalFlip'},\n",
        "        {'type': 'Resize', 'size': [640, 640]},\n",
        "        {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True},\n",
        "        # Keep SanitizeBoundingBoxes after resize if needed\n",
        "        {'type': 'SanitizeBoundingBoxes', 'min_size': 1},\n",
        "        # Keep ConvertBoxes if model expects normalized cxcywh format\n",
        "        {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}\n",
        "    ]\n",
        "\n",
        "    # --- Update the train_dataloader transforms in this included file ---\n",
        "    # Navigate the structure carefully\n",
        "    found_path = False\n",
        "    if 'train_dataloader' in include_config and \\\n",
        "       isinstance(include_config.get('train_dataloader'), dict) and \\\n",
        "       'dataset' in include_config['train_dataloader'] and \\\n",
        "       isinstance(include_config['train_dataloader'].get('dataset'), dict) and \\\n",
        "       'transforms' in include_config['train_dataloader']['dataset'] and \\\n",
        "       isinstance(include_config['train_dataloader']['dataset'].get('transforms'), dict) and \\\n",
        "       'ops' in include_config['train_dataloader']['dataset']['transforms']:\n",
        "\n",
        "        print(\"  Simplifying train_dataloader -> dataset -> transforms -> ops...\")\n",
        "        include_config['train_dataloader']['dataset']['transforms']['ops'] = simplified_train_transforms_ops\n",
        "        found_path = True\n",
        "    else:\n",
        "        # Attempt to find transforms directly under dataset if ops isn't there\n",
        "        if 'train_dataloader' in include_config and \\\n",
        "           isinstance(include_config.get('train_dataloader'), dict) and \\\n",
        "           'dataset' in include_config['train_dataloader'] and \\\n",
        "           isinstance(include_config['train_dataloader'].get('dataset'), dict) and \\\n",
        "           'transforms' in include_config['train_dataloader']['dataset']:\n",
        "             print(\"  Found transforms directly under dataset. Assuming it's a list of ops...\")\n",
        "             # Check if it's already a list (might not need 'ops' key)\n",
        "             if isinstance(include_config['train_dataloader']['dataset']['transforms'], list):\n",
        "                 include_config['train_dataloader']['dataset']['transforms'] = simplified_train_transforms_ops\n",
        "                 found_path = True\n",
        "             # Or if it's a dict with an 'ops' key we missed somehow\n",
        "             elif isinstance(include_config['train_dataloader']['dataset']['transforms'], dict) and \\\n",
        "                  'ops' in include_config['train_dataloader']['dataset']['transforms']:\n",
        "                   print(\"    Re-simplifying train_dataloader -> dataset -> transforms -> ops...\")\n",
        "                   include_config['train_dataloader']['dataset']['transforms']['ops'] = simplified_train_transforms_ops\n",
        "                   found_path = True\n",
        "\n",
        "\n",
        "    if not found_path:\n",
        "        print(\"  Could not find expected structure to simplify transforms in dataloader.yml.\", file=sys.stderr)\n",
        "        print(\"  Please check the file manually: \", include_config_path, file=sys.stderr)\n",
        "\n",
        "\n",
        "    # --- Write the modified content back ---\n",
        "    if found_path:\n",
        "        with open(include_config_path, 'w') as f:\n",
        "            yaml_loader.dump(include_config, f)\n",
        "        print(f\"\\n✅ Successfully simplified transforms in: {include_config_path}\")\n",
        "        print(\"\\n--- Verifying updated file content (showing relevant part): ---\")\n",
        "        !grep -A 20 \"train_dataloader:\" {include_config_path} # Show train_dataloader section\n",
        "        print(\"\\n--- End verification ---\")\n",
        "    else:\n",
        "         print(\"\\n❌ No changes written due to missing config structure.\", file=sys.stderr)\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "     print(f\"❌ Error: File not found at {include_config_path}. Please check the path.\", file=sys.stderr)\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error modifying {include_config_path}: {e}\", file=sys.stderr)\n",
        "    print(f\"   Type: {type(e).__name__}\", file=sys.stderr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWBysZ-QEpNE",
        "outputId": "ed317188-3bec-4a37-dffd-0186affcbffa"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Simplifying Transforms in included file: /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/include/dataloader.yml ---\n",
            "  Simplifying train_dataloader -> dataset -> transforms -> ops...\n",
            "\n",
            "✅ Successfully simplified transforms in: /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/include/dataloader.yml\n",
            "\n",
            "--- Verifying updated file content (showing relevant part): ---\n",
            "train_dataloader:\n",
            "  dataset:\n",
            "    return_masks: false\n",
            "    transforms:\n",
            "      ops:\n",
            "        - type: RandomHorizontalFlip\n",
            "        - type: Resize\n",
            "          size:\n",
            "            - 640\n",
            "            - 640\n",
            "        - type: ConvertPILImage\n",
            "          dtype: float32\n",
            "          scale: true\n",
            "        - type: SanitizeBoundingBoxes\n",
            "          min_size: 1\n",
            "        - type: ConvertBoxes\n",
            "          fmt: cxcywh\n",
            "          normalize: true\n",
            "  collate_fn:\n",
            "    type: BatchImageCollateFuncion\n",
            "    scales: [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800]\n",
            "\n",
            "--- End verification ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 10. (Check/Fix Solver Init - Revised v3) Remove Bad Import ONLY\n",
        "\n",
        "import os\n",
        "\n",
        "init_file_path = '/content/RT-DETR/rtdetrv2_pytorch/src/solver/__init__.py'\n",
        "print(f\"Attempting to remove incorrect import from: {init_file_path}\")\n",
        "\n",
        "try:\n",
        "    with open(init_file_path, 'r') as file:\n",
        "        lines = file.readlines() # Read lines into a list\n",
        "\n",
        "    incorrect_import = \"from src.solver.detection import DetectionSolver\"\n",
        "    original_num_lines = len(lines)\n",
        "    cleaned_lines = []\n",
        "    import_found = False\n",
        "\n",
        "    # Create a new list excluding the incorrect import line\n",
        "    for line in lines:\n",
        "        if incorrect_import in line:\n",
        "            import_found = True\n",
        "            print(f\"  -> Found and skipping line: {line.strip()}\")\n",
        "        else:\n",
        "            cleaned_lines.append(line)\n",
        "\n",
        "    if import_found:\n",
        "        if len(cleaned_lines) < original_num_lines:\n",
        "            print(\"  -> Attempting to write file back without the incorrect import...\")\n",
        "            try:\n",
        "                with open(init_file_path, 'w') as file:\n",
        "                    file.writelines(cleaned_lines) # Write the cleaned lines back\n",
        "                print(\"  ✅ File successfully rewritten.\")\n",
        "\n",
        "                # Optional: Verify content after writing\n",
        "                print(\"\\n--- Verifying file content after removal ---\")\n",
        "                with open(init_file_path, 'r') as file:\n",
        "                   print(file.read())\n",
        "                print(\"--- End of file content ---\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ Failed to write cleaned content back to file: {e}\")\n",
        "        else:\n",
        "            # Should not happen if import_found is True, but as a safeguard\n",
        "            print(\"  ⚠️ Import line found, but line count did not decrease after filtering. No changes made.\")\n",
        "    else:\n",
        "        print(f\"  ✅ Incorrect import '{incorrect_import}' not found. File should be okay.\")\n",
        "        # Optional: Print content anyway for verification\n",
        "        # print(\"\\n--- Current file content ---\")\n",
        "        # with open(init_file_path, 'r') as file:\n",
        "        #    print(file.read())\n",
        "        # print(\"--- End of file content ---\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: Solver init file not found at {init_file_path}. Cannot check/patch.\")\n",
        "except Exception as e:\n",
        "     print(f\"❌ Error processing solver init file: {e}\")"
      ],
      "metadata": {
        "id": "patch_solver",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507c0ed3-a929-4fd4-a3d3-f638866d4f33"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to remove incorrect import from: /content/RT-DETR/rtdetrv2_pytorch/src/solver/__init__.py\n",
            "  ✅ Incorrect import 'from src.solver.detection import DetectionSolver' not found. File should be okay.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 11. Start Training! (Using Main Config with NESTED Overrides)\n",
        "# Ensure we are in the right directory: /content/RT-DETR/rtdetrv2_pytorch\n",
        "%cd /content/RT-DETR/rtdetrv2_pytorch\n",
        "\n",
        "print(\"\\n🚀 Starting Training using main config with NESTED dataset overrides...\")\n",
        "# Use the original main config file - it now contains overrides for the dataloader's dataset section.\n",
        "!python tools/train.py \\\n",
        "    -c configs/rtdetr/rtdetr_r50vd_6x_coco.yml \\\n",
        "    # Add --amp if needed\n",
        "\n",
        "print(\"\\n🏁 Training script finished.\")"
      ],
      "metadata": {
        "id": "start_training",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629e7568-5891-4eac-a8e4-5257dd577a4c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RT-DETR/rtdetrv2_pytorch\n",
            "\n",
            "🚀 Starting Training using main config with NESTED dataset overrides...\n",
            "2025-04-01 11:45:47.994507: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-01 11:45:48.012664: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743507948.034632   56991 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743507948.041368   56991 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-01 11:45:48.063778: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Not init distributed mode.\n",
            "cfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': None, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': None, 'tuning': None, 'epoches': 72, 'last_epoch': -1, 'use_amp': False, 'use_ema': True, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.1, 'find_unused_parameters': False, 'seed': None, 'print_freq': 100, 'checkpoint_freq': 1, 'output_dir': './output/rtdetr_r50vd_6x_visdrone', 'summary_dir': None, 'device': '', 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 10, 'remap_mscoco_category': True, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/content/VisDrone2019-DET-train/images', 'ann_file': '/content/visdrone_train_coco.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'RandomHorizontalFlip'}, {'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}]}}, 'shuffle': True, 'num_workers': 4, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFuncion', 'scales': [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800]}, 'total_batch_size': 16}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/content/VisDrone2019-DET-val/images', 'ann_file': '/content/visdrone_val_coco.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': [640, 640]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 4, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFuncion'}, 'total_batch_size': 16}, 'print_freq': 100, 'output_dir': './output/rtdetr_r50vd_6x_visdrone', 'checkpoint_freq': 1, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': False, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': True, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 2000}, 'epoches': 72, 'clip_max_norm': 0.1, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)(?!.*(?:norm|bn)).*$', 'lr': 1e-05}, {'params': '^(?=.*backbone)(?=.*(?:norm|bn)).*$', 'weight_decay': 0.0, 'lr': 1e-05}, {'params': '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn|bias)).*$', 'weight_decay': 0.0}], 'lr': 0.0001, 'betas': [0.9, 0.999], 'weight_decay': 0.0001}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [1000], 'gamma': 0.1}, 'lr_warmup_scheduler': {'type': 'LinearWarmup', 'warmup_duration': 2000}, 'model': 'RTDETR', 'criterion': 'RTDETRCriterion', 'postprocessor': 'RTDETRPostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [640, 640], 'RTDETR': {'backbone': 'PResNet', 'encoder': 'HybridEncoder', 'decoder': 'RTDETRTransformer'}, 'PResNet': {'depth': 50, 'variant': 'd', 'freeze_at': 0, 'return_idx': [1, 2, 3], 'num_stages': 4, 'freeze_norm': True, 'pretrained': True}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 1024, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 1.0, 'depth_mult': 1, 'act': 'silu', 'version': 'v1'}, 'RTDETRTransformer': {'feat_channels': [256, 256, 256], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'eval_idx': -1}, 'RTDETRPostProcessor': {'num_top_queries': 300}, 'RTDETRCriterion': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2}, 'losses': ['vfl', 'boxes'], 'alpha': 0.75, 'gamma': 2.0, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, '__include__': ['../dataset/coco_detection.yml', '../runtime.yml', './include/dataloader.yml', './include/optimizer.yml', './include/rtdetr_r50vd.yml'], 'config': 'configs/rtdetr/rtdetr_r50vd_6x_coco.yml', 'test_only': False, 'print_method': 'builtin', 'print_rank': 0}}\n",
            "Start training\n",
            "Load PResNet50 state_dict\n",
            "Initial lr: [1e-05, 1e-05, 0.0001, 0.0001]\n",
            "building train_dataloader with batch_size=16...\n",
            "loading annotations into memory...\n",
            "Done (t=1.79s)\n",
            "creating index...\n",
            "index created!\n",
            "building val_dataloader with batch_size=16...\n",
            "loading annotations into memory...\n",
            "Done (t=0.56s)\n",
            "creating index...\n",
            "index created!\n",
            "number of trainable parameters: 42719010\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/RT-DETR/rtdetrv2_pytorch/tools/train.py\", line 65, in <module>\n",
            "    main(args)\n",
            "  File \"/content/RT-DETR/rtdetrv2_pytorch/tools/train.py\", line 35, in main\n",
            "    solver.fit()\n",
            "  File \"/content/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/det_solver.py\", line 38, in fit\n",
            "    train_stats = train_one_epoch(\n",
            "                  ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/RT-DETR/rtdetrv2_pytorch/tools/../src/solver/det_engine.py\", line 38, in train_one_epoch\n",
            "    for i, (samples, targets) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
            "  File \"/content/RT-DETR/rtdetrv2_pytorch/tools/../src/misc/logger.py\", line 215, in log_every\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1480, in _next_data\n",
            "    return self._process_data(data)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1505, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_utils.py\", line 733, in reraise\n",
            "    raise exception\n",
            "NotImplementedError: Caught NotImplementedError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "            ~~~~~~~~~~~~^^^^^\n",
            "  File \"/content/RT-DETR/rtdetrv2_pytorch/tools/../src/data/dataset/coco_dataset.py\", line 41, in __getitem__\n",
            "    img, target, _ = self._transforms(img, target, self)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/RT-DETR/rtdetrv2_pytorch/tools/../src/data/transforms/container.py\", line 46, in forward\n",
            "    return self.get_forward(self.policy['name'])(*inputs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/RT-DETR/rtdetrv2_pytorch/tools/../src/data/transforms/container.py\", line 59, in default_forward\n",
            "    sample = transform(sample)\n",
            "             ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_transform.py\", line 68, in forward\n",
            "    flat_outputs = [\n",
            "                   ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_transform.py\", line 69, in <listcomp>\n",
            "    self.transform(inpt, params) if needs_transform else inpt\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_transform.py\", line 55, in transform\n",
            "    raise NotImplementedError\n",
            "NotImplementedError\n",
            "\n",
            "\n",
            "🏁 Training script finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Display Base Config Content (rtdetr_r50vd_6x_coco.yml)\n",
        "print(\"--- Content of: /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_coco.yml ---\")\n",
        "!cat /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_coco.yml\n",
        "print(\"--- End of file content ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaV3VyIJq88N",
        "outputId": "4c7eee28-afb7-473b-d3e8-017617500c71"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Content of: /content/RT-DETR/rtdetrv2_pytorch/configs/rtdetr/rtdetr_r50vd_6x_coco.yml ---\n",
            "\n",
            "__include__: [\n",
            "  '../dataset/coco_detection.yml',\n",
            "  '../runtime.yml',\n",
            "  './include/dataloader.yml',\n",
            "  './include/optimizer.yml',\n",
            "  './include/rtdetr_r50vd.yml',\n",
            "]\n",
            "\n",
            "\n",
            "output_dir: ./output/rtdetr_r50vd_6x_coco\n",
            "\n",
            "\n",
            "\n",
            "--- End of file content ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 12. (Optional) Evaluate Model on Validation Set\n",
        "# After training finishes, you can evaluate the final model (or a specific checkpoint)\n",
        "import os\n",
        "\n",
        "# Ensure we are in the correct directory\n",
        "%cd /content/RT-DETR/rtdetrv2_pytorch\n",
        "\n",
        "# Path to the final weights (adjust if you saved checkpoints differently)\n",
        "OUTPUT_DIR = \"output/rtdetr_r50vd_6x_visdrone\" # Matches config\n",
        "FINAL_WEIGHTS = os.path.join(OUTPUT_DIR, \"model_final.pth\") # Default save location\n",
        "BEST_CHECKPOINT = os.path.join(OUTPUT_DIR, \"best_checkpoint.pth\") # Common name for best ckpt\n",
        "CONFIG_FILE = \"configs/rtdetr/rtdetr_r50vd_6x_visdrone.yml\"\n",
        "\n",
        "eval_weights = None\n",
        "if os.path.exists(FINAL_WEIGHTS):\n",
        "    eval_weights = FINAL_WEIGHTS\n",
        "elif os.path.exists(BEST_CHECKPOINT):\n",
        "    print(f\"\\n⚠️ Final weights not found at {FINAL_WEIGHTS}. Using best checkpoint instead.\")\n",
        "    eval_weights = BEST_CHECKPOINT\n",
        "else:\n",
        "    print(f\"\\n⚠️ Evaluation skipped: Neither final weights ({FINAL_WEIGHTS}) nor best checkpoint ({BEST_CHECKPOINT}) found.\")\n",
        "    print(\"   Check the 'output_dir' in your config and the training logs.\")\n",
        "\n",
        "if eval_weights:\n",
        "    print(f\"\\n🧪 Evaluating model: {eval_weights}\")\n",
        "    !python tools/eval.py \\\n",
        "        -c {CONFIG_FILE} \\\n",
        "        -w {eval_weights} \\\n",
        "        --amp # Use amp if you trained with it"
      ],
      "metadata": {
        "id": "evaluate_model",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def8c6e1-6390-472c-aea1-b4e0bf2452d0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RT-DETR/rtdetrv2_pytorch\n",
            "\n",
            "⚠️ Evaluation skipped: Neither final weights (output/rtdetr_r50vd_6x_visdrone/model_final.pth) nor best checkpoint (output/rtdetr_r50vd_6x_visdrone/best_checkpoint.pth) found.\n",
            "   Check the 'output_dir' in your config and the training logs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 13. (Optional) Inference on Test Images\n",
        "# Perform inference on a few images from the test set\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Ensure we are in the correct directory\n",
        "%cd /content/RT-DETR/rtdetrv2_pytorch\n",
        "\n",
        "OUTPUT_DIR = \"output/rtdetr_r50vd_6x_visdrone\" # Matches config\n",
        "FINAL_WEIGHTS = os.path.join(OUTPUT_DIR, \"model_final.pth\")\n",
        "BEST_CHECKPOINT = os.path.join(OUTPUT_DIR, \"best_checkpoint.pth\")\n",
        "CONFIG_FILE = \"configs/rtdetr/rtdetr_r50vd_6x_visdrone.yml\"\n",
        "\n",
        "infer_weights = None\n",
        "if os.path.exists(FINAL_WEIGHTS):\n",
        "    infer_weights = FINAL_WEIGHTS\n",
        "elif os.path.exists(BEST_CHECKPOINT):\n",
        "    print(f\"\\n⚠️ Final weights not found. Using best checkpoint for inference.\")\n",
        "    infer_weights = BEST_CHECKPOINT\n",
        "else:\n",
        "    print(f\"\\n⚠️ Inference skipped: Trained weights not found in {OUTPUT_DIR}\")\n",
        "\n",
        "if infer_weights:\n",
        "    print(f\"\\n🖼️ Running inference using weights: {infer_weights}\")\n",
        "\n",
        "    # Path to test images\n",
        "    test_image_dir = \"/content/VisDrone2019-DET-test-dev/images\"\n",
        "    if os.path.exists(test_image_dir):\n",
        "        test_images = glob.glob(os.path.join(test_image_dir, \"*.jpg\"))\n",
        "\n",
        "        if test_images:\n",
        "            # Select a few random images\n",
        "            num_images_to_show = 3\n",
        "            selected_images = random.sample(test_images, min(num_images_to_show, len(test_images)))\n",
        "\n",
        "            output_infer_dir = os.path.join(OUTPUT_DIR, \"inference_results\")\n",
        "            os.makedirs(output_infer_dir, exist_ok=True)\n",
        "\n",
        "            for img_path in selected_images:\n",
        "                print(f\"  -> Processing: {os.path.basename(img_path)}\")\n",
        "                !python tools/infer.py \\\n",
        "                    --infer_img {img_path} \\\n",
        "                    --output_dir {output_infer_dir} \\\n",
        "                    -c {CONFIG_FILE} \\\n",
        "                    -w {infer_weights} \\\n",
        "                    --draw_threshold 0.4 # Adjust confidence threshold for drawing boxes\n",
        "\n",
        "                # Display the result image\n",
        "                result_img_path = os.path.join(output_infer_dir, os.path.basename(img_path))\n",
        "                if os.path.exists(result_img_path):\n",
        "                     print(f\"  -> Result saved to: {result_img_path}\")\n",
        "                     display(Image(filename=result_img_path, width=600))\n",
        "                else:\n",
        "                     print(f\"  -> Output image not found at {result_img_path}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"⚠️ No test images (*.jpg) found in {test_image_dir}\")\n",
        "    else:\n",
        "      print(f\"⚠️ Test image directory not found: {test_image_dir}\")\n"
      ],
      "metadata": {
        "id": "run_inference"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}